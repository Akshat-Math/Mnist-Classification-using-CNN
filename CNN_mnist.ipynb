{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshat-Math/Mnist-Classification-using-CNN/blob/main/CNN_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrXU1ew4lHAX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "e7aDMlZPoh1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "_Cc0Ae3LEGJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "gkLm6Bf2opmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad43966-548d-4f96-aeb5-f6af60352dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding\n",
        "n_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train,n_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test,n_classes)"
      ],
      "metadata": {
        "id": "i_Ih1mm8o2wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_width = 28\n",
        "input_height = 28\n",
        "input_channels = 1\n",
        "input_pixels = 784 #28x28\n",
        "\n",
        "convo_layer_1 = 32  #32 units\n",
        "stride_convo1 = 1\n",
        "convo_layer_2 = 64  #64 units\n",
        "stride_convo2 = 1\n",
        "#5x5 filters for both convolutional layers\n",
        "convo_1_k = 5\n",
        "convo_2_k =5\n",
        "#2x2 filters for both max_pool layers\n",
        "max_pool_k1 = 2\n",
        "max_pool_k2 = 2\n",
        "\n",
        "n_hidden = 1024\n",
        "n_output = 10\n",
        "\n",
        "input_size_to_hidden = 7 * 7 * (convo_layer_2)"
      ],
      "metadata": {
        "id": "xKhwm0kdpPv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1, input_height, input_width, input_channels)\n",
        "x_test = x_test.reshape(-1, input_height, input_width, input_channels)"
      ],
      "metadata": {
        "id": "20092LpsbxSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = { 'wc1' : tf.Variable(tf.random.normal([convo_1_k , convo_1_k , input_channels, convo_layer_1])), #shape of weights for convo layer 1  = 5x5x32x1\n",
        "            'wc2': tf.Variable(tf.random.normal([convo_2_k, convo_2_k, convo_layer_1, convo_layer_2])), #shape of weights for convo layer 1 = 5x5x64x32\n",
        "            'whl' : tf.Variable(tf.random.normal([input_size_to_hidden,n_hidden])), #shape = 7x7x64x1024 = 3136x64\n",
        "            'wop' : tf.Variable(tf.random.normal([n_hidden,n_output]))  #shape = 1024x10\n",
        "          }\n",
        "\n",
        "biases = { 'b1' : tf.Variable(tf.random.normal([convo_layer_1])), #biases for every unit of convo 1 = no. of units = 32\n",
        "           'b2' : tf.Variable(tf.random.normal([convo_layer_2])),\n",
        "           'hl' : tf.Variable(tf.random.normal([n_hidden])),\n",
        "           'op' : tf.Variable(tf.random.normal([n_output])),\n",
        "         }"
      ],
      "metadata": {
        "id": "1K7qYdUFqjo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(x,weights,bias,strides = 1):\n",
        "  #strides ka shape should be same as that of x, so we dont want to skip any image so we kept 1 in starting that is compared to batch size\n",
        "  #height and weight ki jagah we have strides\n",
        "  #for input_channels ki jagah means the depth of filter is 1 cause ek pura block of filter is fitted\n",
        "  out = tf.nn.conv2d(x , weights, padding = \"SAME\" , strides=[1,strides,strides,1])  #applying filter to convo_layer_1\n",
        "  out = tf.nn.bias_add(out,bias)\n",
        "  out = tf.nn.relu(out)\n",
        "\n",
        "  return out\n"
      ],
      "metadata": {
        "id": "OOp7zUVF7Y5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maxpooling(x, k=2):\n",
        "  #ksize = no.of_images x height x width x no.of_channels\n",
        "  return tf.nn.max_pool(x, padding = \"SAME\" , ksize = [1,k,k,1] , strides = [1,k,k,1])"
      ],
      "metadata": {
        "id": "Cd7n7CQ19hug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn(x,weights,biases,keep_prob):\n",
        "  #we need to reshape our input first\n",
        "  #'batch_sizex28x28x1\n",
        "  #batch size so that those all images are reshaped which are in batch\n",
        "  #here -1 says ki mai khud pata laga lunga so wo batch_size khud pata lega\n",
        "   x = tf.reshape(x,shape = (-1,input_height,input_width,input_channels))\n",
        "\n",
        "   convo_layer1_op = conv( x , weights['wc1'] , biases['b1'], stride_convo1)  #output of convolutional layer 1\n",
        "   conv1_pool_op = maxpooling(convo_layer1_op, max_pool_k1) #output of maxpool layer 1\n",
        "\n",
        "   convo_layer2_op = conv( conv1_pool_op,weights['wc2'] , biases['b2'], stride_convo2) #output of convolutional layer 2\n",
        "   conv2_pool_op = maxpooling(convo_layer2_op, max_pool_k2) #output of maxpool layer 2\n",
        "\n",
        "   #reshaping before dense layer\n",
        "   hidden_input = tf.reshape(conv2_pool_op, shape = [-1,input_size_to_hidden] )\n",
        "   hidden_output_before_activation = tf.add(tf.matmul(hidden_input, weights['whl']),biases['hl'])\n",
        "   hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
        "   #dropout layer\n",
        "   hidden_output = tf.nn.dropout(hidden_output_before_dropout, keep_prob)\n",
        "   output = tf.add(tf.matmul(hidden_output,weights['wop']),biases['op'])\n",
        "\n",
        "   return output"
      ],
      "metadata": {
        "id": "4z21dSkUxGAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.compat.v1.placeholder('float32', [None,input_height,input_width,input_channels])  #None represents that we dont know ki how many no. of images will we pass but we know that the features will be 784\n",
        "print(x.shape)\n",
        "y = tf.compat.v1.placeholder('float32',[None,n_output]) #this will be of shape no. of images\n",
        "print(y.shape)\n",
        "keep_prob = tf.compat.v1.placeholder(\"float32\")"
      ],
      "metadata": {
        "id": "CZQqYF8LPp3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eed609c-017a-43ec-9fe0-b52aa1286255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 28, 28, 1)\n",
            "(None, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = cnn(x,weights,biases,keep_prob)"
      ],
      "metadata": {
        "id": "sxxFxJlkZpzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cost fxn, here we use cross entropy\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y)) #logits means predictions here"
      ],
      "metadata": {
        "id": "6JGjVlNyPqJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = 0.01)\n",
        "optimize = optimizer.minimize(cost)"
      ],
      "metadata": {
        "id": "9W80NmQwWY50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = tf.compat.v1.Session()\n",
        "sess.run(tf.compat.v1.global_variables_initializer())"
      ],
      "metadata": {
        "id": "ijs6B_U-WZV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "num_batches = len(x_train) // batch_size\n",
        "\n",
        "for i in range(25):\n",
        "    total_cost = 0\n",
        "    for j in range(num_batches):\n",
        "        start_idx = j * batch_size\n",
        "        end_idx = (j + 1) * batch_size\n",
        "        batch_x, batch_y = x_train[start_idx:end_idx], y_train[start_idx:end_idx]\n",
        "        c, _ = sess.run([cost, optimize], feed_dict={x: batch_x, y: batch_y, keep_prob: 0.8})\n",
        "        total_cost += c\n",
        "    print(total_cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xlYxxy5WZdC",
        "outputId": "dde47a95-aca6-4289-9936-5c91b94f7be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "319704837.5136719\n",
            "1844154.7660565376\n",
            "199939.3951101303\n",
            "44181.9602060318\n",
            "38093.263711333275\n",
            "18837.738605737686\n",
            "17716.1618309021\n",
            "11934.943495035172\n",
            "5725.7557628154755\n",
            "5776.500092744827\n",
            "11326.775836706161\n",
            "20164.10687494278\n",
            "103474.6178996563\n",
            "76069.18829917908\n",
            "5038.784490346909\n",
            "2234.8819806575775\n",
            "26346.89414024353\n",
            "164275.21172523499\n",
            "18451.07860517502\n",
            "1380.9149661064148\n",
            "1380.9356665611267\n",
            "1380.8677780628204\n",
            "1460.7347548007965\n",
            "1380.8235375881195\n",
            "1380.936760187149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = tf.argmax(pred, 1)\n",
        "correct_labels = tf.argmax(y, 1)\n",
        "correct_predictions = tf.equal(predictions, correct_labels)\n",
        "predictions,correct_preds  = sess.run([predictions, correct_predictions], feed_dict={x:x_train,\n",
        "                                              y:y_train, keep_prob:1.0})\n",
        "correct_preds.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmb0MMxPd5y9",
        "outputId": "7d2f23d2-a66d-4f2d-d4eb-c58e449a5d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6265"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0XI/3B56FSamrPnKDY9XH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}